#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse
from collections import namedtuple
import sys


def _print(args, text, **kwargs):
    if not args.quiet:
        print(text, **kwargs)


class Author(namedtuple("Author", ["name", "url"])):
    @property
    def is_me(self):
        return self.name == "Angelos Katharopoulos"

    @property
    def first_name(self):
        return self.name.split(" ")[0]

    @property
    def last_name(self):
        return self.name.split(" ")[1]

    @property
    def initial(self):
        return self.first_name[0]


class Paper(namedtuple("Paper", [
        "title",
        "url",
        "image",
        "authors",
        "conference",
        "year",
        "special",
        "links"
    ])):
    pass


class Conference(namedtuple("Conference", ["name", "short_name"])):
    pass


class Link(namedtuple("Link", ["name", "url", "html", "text"])):
    pass


def author_list(authors, *names):
    return [authors[n] for n in names]


authors = {
    "despi": Author("Despoina Paschalidou", "https://paschalidoud.github.io/"),
    "angelos": Author("Angelos Katharopoulos", ""),
    "diou": Author("Christos Diou", "https://mug.ee.auth.gr/people/christos-diou/"),
    "delo": Author("Anastasios Delopoulos", "https://mug.ee.auth.gr/people/anastasios-delopoulos/"),
    "frankie": Author("François Fleuret", "https://fleuret.org/francois"),
    "apoorv": Author("Apoorv Vyas", "https://idiap.ch/~avyas"),
    "nikos": Author("Nikolaos Pappas", "https://nik0spapp.github.io/"),
    "ageiger": Author("Andreas Geiger", "http://www.cvlibs.net/"),
    "sfidler": Author("Sanja Fidler", "https://www.cs.utoronto.ca/~fidler/")
}

conferences = {
    "preprint": Conference("", "Preprint"),
    "cvpr": Conference("Computer Vision and Pattern Recognition", "CVPR"),
    "neurips": Conference("Neural Information Processing Systems", "NeurIPS"),
    "icml": Conference("International Conference on Machine Learning", "ICML"),
    "eusipco": Conference("European Signal Processing Conference", "EUSIPCO"),
    "acmmm": Conference("ACM Multimedia Conference", "ACMM")
}

publications = [
    Paper(
        "Neural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks",
        "https://paschalidoud.github.io/neural_parts",
        "imgs/teasers/neural_parts.png",
        author_list(authors, "despi", "angelos", "ageiger", "sfidler"),
        conferences["cvpr"],
        2021,
        None,
        [
            Link("Abstract", None,
                 ("Impressive progress in 3D shape extraction led to "
                  "representations that can capture object geometries with high "
                  "fidelity. In parallel, primitive-based methods seek to "
                  "represent objects as semantically consistent part "
                  "arrangements. However, due to the simplicity of existing "
                  "primitive representations, these methods fail to accurately "
                  "reconstruct 3D shapes using a small number of "
                  "primitives/parts. We address the trade-off between "
                  "reconstruction quality and number of parts with Neural Parts, "
                  "a novel 3D primitive representation that defines primitives "
                  "using an Invertible Neural Network (INN) which implements "
                  "homeomorphic mappings between a sphere and the target object. "
                  "The INN allows us to compute the inverse mapping of the "
                  "homeomorphism, which in turn, enables the efficient "
                  "computation of both the implicit surface function of a "
                  "primitive and its mesh, without any additional "
                  "post-processing. Our model learns to parse 3D objects into "
                  "semantically consistent part arrangements without any "
                  "part-level supervision. Evaluations on ShapeNet, D-FAUST and "
                  "FreiHAND demonstrate that our primitives can capture complex "
                  "geometries and thus simultaneously achieve geometrically "
                  "accurate as well as interpretable reconstructions using an "
                  "order of magnitude fewer primitives than state-of-the-art "
                  "shape abstraction methods."),
                 None),
            Link("Paper", "https://arxiv.org/pdf/2103.10429", None, None),
            Link("Explore", "https://paschalidoud.github.io/neural_parts", None, None),
            Link("Video", "https://www.youtube.com/watch?v=6WK3B0IZJsw", None, None),
            Link("Poster", "https://paschalidoud.github.io/data/Paschalidou2021CVPR_poster.pdf", None, None),
            Link("Code", "https://github.com/paschalidoud/neural_parts", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{paschalidou2021nps,\n"
                  "    title={Neural Parts: Learning Expressive 3D Shape "
                  "Abstractions with Invertible Neural Networks},\n"
                  "    author={Paschalidou, D. and Katharopoulos, A. and "
                  "Geiger, A. and Fidler, S.},\n"
                  "    booktitle={{Proceedings IEEE Conf. on Computer Vision "
                  "and Pattern Recognition (CVPR)}},\n"
                  "    year={2021},\n"
                  "    url={https://arxiv.org/pdf/2103.10429}\n"
                  "}"))
        ]
    ),

    Paper(
        "Fast Transformers with Clustered Attention",
        "https://clustered-transformers.github.io",
        "imgs/teasers/clustered_attention.png",
        author_list(authors, "apoorv", "angelos", "frankie"),
        conferences["neurips"],
        2020,
        None,
        [
            Link("Abstract", None,
                 ("Transformers have been proven a successful model for a "
                  "variety of tasks in sequence modeling. However, computing the "
                  "attention matrix, which is their key component, has quadratic "
                  "complexity with respect to the sequence length, thus making "
                  "them prohibitively expensive for large sequences. To address "
                  "this, we propose clustered attention, which instead of "
                  "computing the attention for every query, groups queries into "
                  "clusters and computes attention just for the centroids. To "
                  "further improve this approximation, we use the computed "
                  "clusters to identify the keys with the highest attention per "
                  "query and compute the exact key/query dot products. This "
                  "results in a model with linear complexity with respect to the "
                  "sequence length for a fixed number of clusters. We evaluate "
                  "our approach on two automatic speech recognition datasets and "
                  "show that our model consistently outperforms vanilla "
                  "transformers for a given computational budget. Finally, we "
                  "demonstrate that our model can approximate arbitrarily complex "
                  "attention distributions with a minimal number of clusters by "
                  "approximating a pretrained BERT model on GLUE and SQuAD "
                  "benchmarks with only 25 clusters and no loss in "
                  "performance."),
                 None),
            Link("Paper", "https://arxiv.org/pdf/2007.04825", None, None),
            Link("Code", "https://github.com/idiap/fast-transformers", None, None),
            Link("Bibtex", None, None,
                 ("@article{vyas_et_al_2020,\n"
                  "    author={Vyas, A. and Katharopoulos, A. and Fleuret, F.},\n"
                  "    title={Fast Transformers with Clustered Attention},\n"
                  "    booktitle={Proceedings of the international conference "
                  "on Neural Information Processing Systems (NeurIPS)},\n"
                  "    year={2020}\n"
                  "}"))
        ]
    ),

    Paper(
        "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention",
        "https://linear-transformers.com",
        "imgs/teasers/transformer_rnn.png",
        author_list(authors, "angelos", "apoorv", "nikos", "frankie"),
        conferences["icml"],
        2020,
        None,
        [
            Link("Abstract", None,
                 ("Transformers achieve remarkable performance in several tasks "
                  "but due to their quadratic complexity, with respect to the "
                  "input’s length, they are prohibitively slow for very long "
                  "sequences. To address this limitation, we express the "
                  "self-attention as a linear dot-product of kernel feature maps "
                  "and make use of the associativity property of matrix products to "
                  "reduce the complexity from O(N<sup>2</sup>) to O(N), where N "
                  "is the sequence length. We show that this formulation permits an "
                  "iterative implementation that dramatically accelerates "
                  "autoregressive transformers and reveals their relationship "
                  "to recurrent neural networks. Our linear transformers achieve "
                  "similar performance to vanilla transformers and they are up to "
                  "4000x faster on autoregressive prediction of very "
                  "long sequences."),
                 None),
            Link("Paper", "https://arxiv.org/pdf/2006.16236.pdf", None, None),
            Link("Explore", "https://colab.research.google.com/drive/1BV4OaWRAHYGeimO0cqHD86GfnfgUaKD4?usp=sharing", None, None),
            Link("Video", "https://youtu.be/KBWh7XCUAi8", None, None),
            Link("Slides", "data/linear_transformers_slides.pdf", None, None),
            Link("Code", "https://github.com/idiap/fast-transformers", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{katharopoulos2020lin,\n"
                  "    title={Transformers are RNNs: Fast Autoregressive Transformers "
                  "with Linear Attention},\n"
                  "    author={Katharopoulos, A. and Vyas, A. and Pappas, N. and Fleuret, F.},\n"
                  "    booktitle={Proceedings of the International Conference on Machine "
                  "Learning (ICML)},\n"
                  "    year={2020},\n"
                  "    url={https://arxiv.org/pdf/2006.16236.pdf}\n"
                  "}"))
        ]
    ),

    Paper(
        "Processing Megapixel Images with Deep Attention-Sampling Models",
        "https://attention-sampling.com/",
        "imgs/teasers/speed_limits.png",
        author_list(authors, "angelos", "frankie"),
        conferences["icml"],
        2019,
        None,
        [
            Link("Abstract", None,
                 ("Existing deep architectures cannot operate on very large "
                  "signals such as megapixel images due to computational and "
                  "memory constraints. To tackle this limitation, we propose a "
                  "fully differentiable end-to-end trainable model that samples "
                  "and processes only a fraction of the full resolution input "
                  "image. The locations to process are sampled from an attention "
                  "distribution computed from a low resolution view of the input. "
                  "We refer to our method as attention sampling and it can "
                  "process images of several megapixels with a standard single "
                  "GPU setup. We show that sampling from the attention "
                  "distribution results in an unbiased estimator of the full "
                  "model with minimal variance, and we derive an unbiased "
                  "estimator of the gradient that we use to train our model "
                  "end-to-end with a normal SGD procedure. This new method is "
                  "evaluated on three classification tasks, where we show that it "
                  "allows to reduce computation and memory footprint by an order "
                  "of magnitude for the same accuracy as classical architectures. "
                  "We also show the consistency of the sampling that indeed "
                  "focuses on informative parts of the input images."),
                 None),
            Link("Paper", "https://arxiv.org/pdf/1905.03711.pdf", None, None),
            Link("Poster", "data/ats_icml_poster.pdf", None, None),
            Link("Slides", "data/ats_icml_slides.pdf", None, None),
            Link("Code", "https://github.com/idiap/attention-sampling", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{katharopoulos2019ats,\n"
                  "    title={Processing Megapixel Images with Deep Attention-Sampling "
                  "Models},\n"
                  "    author={Katharopoulos, A. and Fleuret, F.},\n"
                  "    booktitle={Proceedings of the International Conference on Machine "
                  "Learning (ICML)},\n"
                  "    year={2019},\n"
                  "    type={Short oral},\n"
                  "    url={https://arxiv.org/pdf/1905.03711.pdf}\n"
                  "}"))
        ]
    ),

    Paper(
        "Not All Samples Are Created Equal: Deep Learning with Importance Sampling",
        "https://importance-sampling.com/",
        "imgs/teasers/variance_reduction.png",
        author_list(authors, "angelos", "frankie"),
        conferences["icml"],
        2018,
        None,
        [
            Link("Abstract", None,
                 ("Deep neural network training spends most of the computation "
                  "on examples that are properly handled, and could be "
                  "ignored. We propose to mitigate this phenomenon with "
                  "a principled importance sampling scheme that focuses "
                  "computation  on  “informative”  examples, and reduces the "
                  "variance of the stochastic gradients during training. Our "
                  "contribution is twofold: first, we derive a tractable upper "
                  "bound to the per-sample gradient norm, and second we derive "
                  "an estimator of the variance reduction achieved with importance "
                  "sampling, which enables us to switch it on when it will result "
                  "in an actual speedup. The resulting scheme can be used by "
                  "changing a few lines of code in a standard SGD procedure, and "
                  "we demonstrate experimentally, on image classification, CNN "
                  "fine-tuning, and RNN training, that for a fixed wall-clock "
                  "time budget, it provides a reduction of the train losses of up "
                  "to an order of magnitude and a relative improvement of test "
                  "errors between 5% and 17%."),
                 None),
            Link("Paper", "https://arxiv.org/pdf/1803.00942.pdf", None, None),
            Link("Poster", "data/is_icml_poster.pdf", None, None),
            Link("Slides", "data/is_icml_slides.pdf", None, None),
            Link("Code", "https://github.com/idiap/importance-sampling", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{katharopoulos2018is,\n"
                  "    title={Not All Samples Are Created Equal: Deep Learning with "
                  "Importance Sampling},\n"
                  "    author={Katharopoulos, A. and Fleuret, F.},\n"
                  "    booktitle={Proceedings of the International Conference on Machine "
                  "Learning (ICML)},\n"
                  "    year={2018},\n"
                  "    type={Short oral},\n"
                  "    url={https://arxiv.org/pdf/1803.00942.pdf}\n"
                  "}"))
        ]
    ),

    Paper(
        "Learning local feature aggregation functions with backpropagation",
        "https://arxiv.org/pdf/1706.08580.pdf",
        "imgs/teasers/local_feature_aggregation.png",
        author_list(authors, "despi", "angelos", "diou", "delo"),
        conferences["eusipco"],
        2017,
        None,
        [
            Link("Abstract", None,
                 ("This paper introduces a family of local feature aggregation "
                  "functions and a novel method to estimate their parameters, "
                  "such that they generate optimal representations for "
                  "classification (or any task that can be expressed as a cost "
                  "function minimization problem). To achieve that, we compose "
                  "the local feature aggregation function with the classifier "
                  "cost function and we backpropagate the gradient of this cost "
                  "function in order to update the local feature aggregation "
                  "function parameters. Experiments on synthetic datasets "
                  "indicate that our method discovers parameters that model the "
                  "class-relevant information in addition to the local feature "
                  "space. Further experiments on a variety of motion and visual "
                  "descriptors, both on image and video datasets, show that our "
                  "method outperforms other state-of-the-art local feature "
                  "aggregation functions, such as Bag of Words, Fisher Vectors "
                  "and VLAD, by a large margin."),
                  None),
            Link("Paper", "https://arxiv.org/pdf/1706.08580.pdf", None, None),
            Link("Poster", "data/eusipco_poster.pdf", None, None),
            Link("Code", "https://github.com/paschalidoud/feature-aggregation", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{katharopoulos2017learning\n"
                  "      title = {Learning local feature aggregation functions "
                  "with backpropagation},\n"
                  "      author = {Paschalidou, Despoina and Katharopoulos, Angelos "
                  "and Diou, Christos and Delopoulos, Anastasios},\n"
                  "      publisher = {IEEE},\n"
                  "      month = aug,\n"
                  "      year = {2017},\n"
                  "      url = {http://ieeexplore.ieee.org/Abstract/document/8081307/},\n"
                  "}"))
        ]
    ),

    Paper(
        "Fast Supervised LDA for Discovering Micro-Events in Large-Scale Video Datasets",
        "http://ldaplusplus.com", # "https://mug.ee.auth.gr/wp-content/uploads/fsLDA.pdf",
        "imgs/teasers/fslda.png",
        author_list(authors, "angelos", "despi", "diou", "delo"),
        conferences["acmmm"],
        2016,
        None,
        [
            Link("Abstract", None, 
                 ("This paper introduces fsLDA, a fast variational inference "
                  "method for supervised LDA, which overcomes the computational "
                  "limitations of the original supervised LDA and enables its "
                  "application in large-scale video datasets. In addition to its "
                  "scalability, our method also overcomes the drawbacks of "
                  "standard, unsupervised LDA for video, including its focus on "
                  "dominant but often irrelevant video information (e.g. "
                  "background, camera motion). As a result, experiments in the "
                  "UCF11 and UCF101 datasets show that our method consistently "
                  "outperforms unsupervised LDA in every metric. Furthermore, "
                  "analysis shows that class-relevant topics of fsLDA lead to "
                  "sparse video representations and encapsulate high-level "
                  "information corresponding to parts of video events, which we "
                  "denote 'micro-events'"),
                 None),
            # Link("Project page", "http://ldaplusplus.com", None, None),
            Link("Paper", "https://mug.ee.auth.gr/wp-content/uploads/fsLDA.pdf", None, None),
            Link("Poster", "data/fslda_poster.pdf", None, None),
            Link("Code", "https://github.com/angeloskath/supervised-lda", None, None),
            Link("Blog", "https://mug.ee.auth.gr/discovering-micro-events-video-data-using-topic-modeling/", None, None),
            Link("Bibtex", None, None,
                 ("@inproceedings{katharopoulos2016fast\n"
                  "        title = {Fast Supervised LDA for Discovering Micro-Events "
                  "in Large-Scale Video Datasets},\n"
                  "        author = {Katharopoulos, Angelos and Paschalidou, Despoina and "
                  "Diou, Christos and Delopoulos, Anastasios},\n"
                  "        booktitle = {Proceedings of the 2016 ACM on Multimedia Conference},\n"
                  "        pages = {332,336},\n"
                  "        month = oct,\n"
                  "        year = {2016},\n"
                  "        url = {http://dl.acm.org/citation.cfm?id=2967237},\n"
                  "        month_numeric = {10}\n"
                  "}"))
        ]
    )
]


def build_publications_list(publications):
    def image(paper):
        if paper.image is not None:
            return '<img src="{}" alt="{}" />'.format(
                paper.image, paper.title
            )
        else:
            return '&nbsp;'

    def title(paper):
        return '<a href="{}">{}</a>'.format(paper.url, paper.title)

    def authors(paper):
        def author(author):
            if author.is_me:
                return '<strong class="author">{}. {}</strong>'.format(
                    author.initial, author.last_name
                )
            else:
                return '<a href="{}" class="author">{}. {}</a>'.format(
                    author.url, author.initial, author.last_name
                )
        return "".join(author(a) for a in paper.authors)

    def conference(paper):
        cf = '{}, {}'.format(paper.conference.short_name, paper.year)
        if paper.special is not None:
            cf = cf + '<span class="special">   ({})</span>'.format(paper.special)
        return cf

    def links(paper):
        def links_list(paper):
            def link(i, link):
                if link.url is not None:
                    # return '<a href="{}">{}</a>'.format(link.url, link.name)
                    return '<a href="{}" data-type="{}">{}</a>'.format(link.url, link.name, link.name)
                else:
                    return '<a href="#" data-type="{}" data-index="{}">{}</a>'.format(link.name, i, link.name)
            return "".join(
                link(i, l) for i, l in enumerate(paper.links)
            )

        def links_content(paper):
            def content(i, link):
                if link.url is not None:
                    return ""
                return '<div class="link-content" data-index="{}">{}</div>'.format(
                    i, link.html if link.html is not None
                       else '<pre>' + link.text + "</pre>"
                )
            return "".join(content(i, link) for i, link in enumerate(paper.links))
        return links_list(paper) + links_content(paper)

    def paper(p):
        return ('<div class="paper">'
                    '<div class="image">{}</div>'
                    '<div class="content">'
                        '<div class="paper-title">{}</div>'
                        '<div class="authors">{}</div>'
                        '<div class="conference">{}</div>'
                        '<div class="links">{}</div>'
                    '</div>'
                    '<div class="clear"></div>'
                '</div>').format(
                    image(p),
                    title(p),
                    authors(p),
                    conference(p),
                    links(p)
                )

    return "".join(paper(p) for p in publications)


def main(argv):
    parser = argparse.ArgumentParser(
        description="Create a publication list and insert in into an html file"
    )
    parser.add_argument(
        "file",
        help="The html file to insert the publications to"
    )

    parser.add_argument(
        "--safe", "-s",
        action="store_true",
        help="Do not overwrite the file but create one with suffix .new"
    )
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="Do not output anything to stdout/stderr"
    )

    args = parser.parse_args(argv)

    # Read the file
    with open(args.file) as f:
        html = f.read()

    # Find the fence comments
    start_text = "<!-- start publication list -->"
    end_text = "<!-- end publication list -->"
    start = html.find(start_text)
    end = html.find(end_text, start)
    if end < start or start < 0:
        _print(args, "Could not find the fence comments", file=sys.stderr)
        sys.exit(1)

    # Build the publication list in html
    replacement = build_publications_list(publications)

    # Update the html and save it
    html = html[:start+len(start_text)] + replacement + html[end:]

    # If safe is set do not overwrite the input file
    if args.safe:
        with open(args.file + ".new", "w") as f:
            f.write(html)
    else:
        with open(args.file, "w") as f:
            f.write(html)


if __name__ == "__main__":
    main(None)
